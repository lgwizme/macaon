#summary Module de découpage des phrases en atomes.

*Voir aussi :* InstallationDeMacaon, TagsetTokenizer
 
=maca_tokenizer=

Découpe les phrases d'un document en unités indivisibles.

|| *Responsable* ||AlejandroAcosta||
|| *Langage* ||C/Python||
|| *Dernière version* ||1.5.2||
|| *Date* ||16/10/2007||
|| *URL* ||[http://www.linguist.jussieu.fr/~aacosta/macaon/modules/maca_tokenizer-1.5.2.tar.gz maca_tokenizer-1.5.2]||

Avec l'installation de ce module, la librarie python 'pytok', contenant une seule fonction: 'lex' est aussi installée.

=== Dépendances ===
 * Librairies et programmes externes
   * python-dev
   * [http://flex.sourceforge.net/ flex]
   * [http://pyxml.sourceforge.net/ PyXML]

=== Commande ===
{{{
USAGE  : maca_tokenizer [OPTIONS]
OPTIONS:
    -h,--help             show this message
    -v,--verbose          print messages
    -i,--input <file>     read input from <file> (defualt is stdin)
    -o,--output <file>    wite output to <file> (default is stdout)
    -b,--batch <dir>      batch mode : (destructively) process files in <dir>
    -e,--element <name>   name of the element to tokenize (default is text)
    -t,--tokens <name>    name of the token element (default is token)
    -n,--no name[,name]*  don't output: id (<token> attribute)
                                        type (<token> attribute)
                                        pos (<token> attribute)
                                        count (<tokens> attribute)
                                        space (space tokens)
                                        space-id ('space' <token> attribute)
                                        unknown (unknown character tokens)
                                        timestamp (module timestamp)

eg. cat input.xml | maca_tokenizer -e text -t token -v -n id,space -v
}}} 

== Entrée ==
Le tokenizer cherche les éléments <text> dans les <sentence>s du document XML.

{{{
<!ELEMENT sentence (text)
          id ID #REQUIRED >

<!ELEMENT text (#PCDATA) >
}}}

== Sortie ==
Le tokenizer ajoute une liste de <token>s  typés dans un élément <tokens> qui suit l'élément <text> dans les phrases du document. 

{{{
<!ELEMENT sentence (text,tokens)
          id ID #REQUIRED >

<!ELEMENT text (#PCDATA) >

<!ELEMENT tokens (token+) >
<!ATTLIST tokens
          count CDATA #IMPLIED >

<!ELEMENT token (#PCDATA) >
<!ATTLIST token
          type CDATA #IMPLIED
          id ID #REQUIRED >
}}}

== Historique des révisions ==

|| *Date* || *Version* || *URL* ||
||2007/10/16||1.5.2||[http://www.linguist.jussieu.fr/~aacosta/macaon/modules/maca_tokenizer-1.5.2.tar.gz maca_tokenizer-1.5.2.tar.gz]|
||2007/09/18||1.5.1||[http://www.linguist.jussieu.fr/~aacosta/macaon/modules/maca_tokenizer-1.5.1.tar.gz maca_tokenizer-1.5.1.tar.gz]||
||2007/06/22||1.5||[http://www.linguist.jussieu.fr/~aacosta/macaon/modules/maca_tokenizer-1.5.tar.gz maca_tokenizer-1.5.tar.gz]||
||2007/06/20||1.4||[http://www.linguist.jussieu.fr/~aacosta/macaon/modules/maca_tokenizer-1.4.tar.gz maca_tokenizer-1.4.tar.gz]||
||2007/05/29||1.3||[http://www.linguist.jussieu.fr/~aacosta/macaon/modules/maca_tokenizer-1.3.tar.gz maca_tokenizer-1.3.tar.gz]||
||2007/02/09||1.2.2||[http://www.linguist.jussieu.fr/~aacosta/macaon/modules/maca_tokenizer-1.2.2.tar.gz maca_tokenizer-1.2.2.tar.gz]||
||2006/12/16||1.2.1||[http://www.linguist.jussieu.fr/~aacosta/macaon/modules/maca_tokenizer-1.2.1.tar.gz maca_tokenizer-1.2.1.tar.gz]||
||2006/11/30||1.2||[http://www.linguist.jussieu.fr/~aacosta/macaon/modules/macatokenizer-1.2.tar.gz macatokenizer-1.2.tar.gz]||
||2006/09/27||1.1||[http://www.linguist.jussieu.fr/~aacosta/macaon/modules/macatokenizer-1.1.tar.gz macatokenizer-1.1.tar.gz]||
 
 